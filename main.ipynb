{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_files(folder_path):\n",
    "    dir_path = Path(folder_path)\n",
    "    pdf_files = list(dir_path.glob(\"*.pdf\"))\n",
    "    return pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extracted_text(file_path):\n",
    "    pdf_files = get_pdf_files(file_path)\n",
    "    text_file = {}\n",
    "    for pdf_file in pdf_files:\n",
    "        file_string = str(pdf_file)\n",
    "        pdf_name = file_string.split('\\\\')[-1]\n",
    "        pdf_identifier = pdf_name.split(\".\")[1]\n",
    "\n",
    "        extracted_text = extract_text_from_pdf(pdf_file)\n",
    "        text_file[pdf_identifier] = extracted_text\n",
    "        print(f\"Text from {pdf_file} added into {pdf_identifier}\")\n",
    "\n",
    "    print(\"Completed text extraction\")\n",
    "    return text_file\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to split the texts, chunk them and add the text chunks to the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j\\.vscode\\Resume_search\\resume-search\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_texts(text_file, model):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=200)\n",
    "\n",
    "    pdf_docs = [{\"page_content\": text, \"metadata\": {\"file_id\": file_id}} for file_id, text in text_file.items()]\n",
    "\n",
    "    splits = text_splitter.split_documents(pdf_docs)\n",
    "\n",
    "    print(\"Splitting completed\")\n",
    "\n",
    "    embeddings = [model.encode(split).tolist() for split in splits]\n",
    "\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j\\.vscode\\Resume_search\\resume-search\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from C:\\Users\\j\\.vscode\\Resume_search\\novelIdeas\\data\\2409.10031v1.pdf added into 10031v1\n",
      "Text from C:\\Users\\j\\.vscode\\Resume_search\\novelIdeas\\data\\2409.10949v1.pdf added into 10949v1\n",
      "Text from C:\\Users\\j\\.vscode\\Resume_search\\novelIdeas\\data\\2409.11303v1.pdf added into 11303v1\n",
      "Text from C:\\Users\\j\\.vscode\\Resume_search\\novelIdeas\\data\\2409.11409v1.pdf added into 11409v1\n",
      "Text from C:\\Users\\j\\.vscode\\Resume_search\\novelIdeas\\data\\2409.13142v1.pdf added into 13142v1\n",
      "Completed text extraction\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m text_file \u001b[38;5;241m=\u001b[39m add_extracted_text(path)\n\u001b[1;32m----> 4\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43msplit_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[137], line 6\u001b[0m, in \u001b[0;36msplit_texts\u001b[1;34m(text_file, model)\u001b[0m\n\u001b[0;32m      2\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m      4\u001b[0m pdf_docs \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage_content\u001b[39m\u001b[38;5;124m\"\u001b[39m: text, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: file_id}} \u001b[38;5;28;01mfor\u001b[39;00m file_id, text \u001b[38;5;129;01min\u001b[39;00m text_file\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m----> 6\u001b[0m splits \u001b[38;5;241m=\u001b[39m \u001b[43mtext_splitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_docs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplitting completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m [model\u001b[38;5;241m.\u001b[39mencode(split)\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m splits]\n",
      "File \u001b[1;32mc:\\Users\\j\\.vscode\\Resume_search\\resume-search\\Lib\\site-packages\\langchain_text_splitters\\base.py:94\u001b[0m, in \u001b[0;36mTextSplitter.split_documents\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m     92\u001b[0m texts, metadatas \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[1;32m---> 94\u001b[0m     texts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m)\n\u001b[0;32m     95\u001b[0m     metadatas\u001b[38;5;241m.\u001b[39mappend(doc\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_documents(texts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "path = 'C:/Users/j/.vscode/Resume_search/novelIdeas/data'\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "text_file = add_extracted_text(path)\n",
    "retriever = split_texts(text_file, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LANGCHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain_fireworks import ChatFireworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderPath = \"C:/Users/j/.vscode/Resume_search/novelIdeas/data\"\n",
    "loader = PyPDFDirectoryLoader(folderPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j\\.vscode\\Resume_search\\resume-search\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "hfEmbedding = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=splits, embedding=hfEmbedding)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"accounts/fireworks/models/llama-v3p1-405b-instruct\"\n",
    "fireworks_llm = ChatFireworks(\n",
    "    model=MODEL_ID,\n",
    "    temperature = 0.6,\n",
    "    max_tokens = 16384,\n",
    "    model_kwargs={\n",
    "        \"top_p\": 1,\n",
    "    },\n",
    "    cache=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"\"\"\n",
    "    Innovation is seeing what everybody has seen and thinking what nobody has thought.\n",
    "    An idea is nothing more nor less than a new combination of old elements. \n",
    "    It can be a thought or suggestion aimed at solving a problem or exploring a possibility.\n",
    "    Ideas challenge, shift paradigms, and drive innovation by synthesizing information, reflection, and imagination. \n",
    "    As a research scientist, your role is to generate new ideas and innovations based on a research paper.\"\"\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = (\n",
    "    \"\"\"\n",
    "    You are a research scientist following the Diagram of Thought (DoT) framework to generate ideas from a research paper. Your workflow will transition through three roles: Proposer, Critic, and Summarizer.\n",
    "    \n",
    "    **1. <Proposer>:** \n",
    "    - **Process**: Analyze the research paper on the topic: {input}\n",
    "    - **Reflect**: Examine prior knowledge, look for patterns, and break down complex concepts. Critically assess assumptions and concepts to gain insights.\n",
    "    - **Imagine**: Use the insights to brainstorm new ideas and generate novel concepts or solutions beyond what is already known. Store these in a list called 'Idea list.'\n",
    "    - **Output**: 'Idea list' = {{proposed_ideas}}\n",
    "    - If no ideas are generated or {{proposed_ideas}} is empty, respond with: \"No ideas proposed.\"\n",
    "\n",
    "    **2. <Critic>**:\n",
    "    - **Evaluate Relevancy**: Ensure the ideas in {{proposed_ideas}} are relevant to the research paper. An idea is not relevant if it seems unrelated to the research the paper. An idea is relevant if it aligns with the research paper. Remove irrelevant ideas from {{proposed_ideas}}, creating {{relevant_ideas}}.\n",
    "    - **Evaluate Novelty**: Assess the originality/novelty of the ideas in {{relevant_ideas}}. An idea is not novel if it is generic, already exists, or has already been explored by numerous researchers. An idea is novel if it represents a good direction, highly innovative, and has been explored by only few or no researchers. Remove unnoriginal ideas from {{relevant_ideas}}, resulting in {{novel_ideas}}.\n",
    "    - **Evaluate Feasiblity**: Review {{novel_ideas}} for factual correctness and practicality. An idea is not feasible if it doesn't make any sense, impractical, or not realistic. An idea is feasible if it is practical and realistic even to a minimal degree. Remove any unrealistic or impractical ideas from {{novel_ideas}}, creating {{refined_ideas}}.\n",
    "    - If {{refined_ideas}} is empty after the critique process, respond with: \"No ideas after critique.\".\n",
    "    \n",
    "    **3. <Summarizer>**:\n",
    "    - Synthesize the remaining ideas from {{refined_ideas}} and write a concise summary for each idea in bullet points.  Begin the summary with: \"Potential top future research ideas from the paper are:\"\n",
    "\n",
    "    \"\\n\\n\"\n",
    "    \"{input}\"\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", human_prompt),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea_generation_chain = create_stuff_documents_chain(fireworks_llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea_retriever_chain = create_retrieval_chain(retriever, idea_generation_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = idea_retriever_chain.invoke({\"input\": \"CyberNFTs: Conceptualizing a decentralized and reward-driven intrusion detection system with ML\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**1. <Proposer>**\n",
      "\n",
      "After analyzing the research paper \"CyberNFTs: Conceptualizing a decentralized and reward-driven intrusion detection system with ML\", I reflected on the concepts and broke down complex ideas to gain insights. Here are some potential ideas that came to mind:\n",
      "\n",
      "* Using blockchain-based systems for decentralized threat intelligence sharing\n",
      "* Developing a machine learning-powered intrusion detection system that leverages cyberNFTs for reward-driven detection\n",
      "* Exploring the application of cyberNFTs in other areas of cybersecurity, such as incident response and threat hunting\n",
      "* Investigating the use of decentralized autonomous organizations (DAOs) for managing and maintaining decentralized intrusion detection systems\n",
      "* Designing a framework for evaluating the effectiveness of decentralized intrusion detection systems in various network environments\n",
      "* Developing a system for detecting and mitigating advanced persistent threats (APTs) using a combination of machine learning and cyberNFTs\n",
      "* Investigating the potential of using cyberNFTs for secure and decentralized data sharing in IoT networks\n",
      "\n",
      "**Output**: 'Idea list' = {proposed_ideas} = 7 ideas\n",
      "\n",
      "**2. <Critic>**\n",
      "\n",
      "Evaluating the relevancy of the proposed ideas, I removed the following ideas that seemed unrelated to the research paper:\n",
      "\n",
      "* Investigating the use of decentralized autonomous organizations (DAOs) for managing and maintaining decentralized intrusion detection systems (while related to decentralization, it's not directly related to the paper's focus on cyberNFTs and intrusion detection)\n",
      "* Designing a framework for evaluating the effectiveness of decentralized intrusion detection systems in various network environments (while relevant to intrusion detection, it's not specific to cyberNFTs)\n",
      "\n",
      "The remaining ideas are relevant to the research paper.\n",
      "\n",
      "Evaluating the novelty of the remaining ideas, I removed the following ideas that are not particularly original or have already been explored:\n",
      "\n",
      "* Using blockchain-based systems for decentralized threat intelligence sharing (while still a relevant area of research, it's not a new idea)\n",
      "* Developing a machine learning-powered intrusion detection system that leverages cyberNFTs for reward-driven detection (this is already the main focus of the research paper)\n",
      "\n",
      "The remaining ideas are novel and represent a good direction for future research.\n",
      "\n",
      "Evaluating the feasibility of the remaining ideas, I removed the following idea that is not practical or realistic:\n",
      "\n",
      "* Developing a system for detecting and mitigating advanced persistent threats (APTs) using a combination of machine learning and cyberNFTs (while an interesting idea, it's a very complex and challenging problem that may not be feasible with current technology)\n",
      "\n",
      "The remaining ideas are feasible and practical.\n",
      "\n",
      "**Output**: 'refined_ideas' = 3 ideas\n",
      "\n",
      "**3. <Summarizer>**\n",
      "\n",
      "Potential top future research ideas from the paper are:\n",
      "\n",
      "* **Exploring the application of cyberNFTs in other areas of cybersecurity, such as incident response and threat hunting**: This idea involves investigating the potential of using cyberNFTs in other areas of cybersecurity beyond intrusion detection. This could include using cyberNFTs to incentivize incident response teams or to track and analyze threat hunting efforts.\n",
      "* **Investigating the potential of using cyberNFTs for secure and decentralized data sharing in IoT networks**: This idea involves exploring the use of cyberNFTs for secure and decentralized data sharing in IoT networks. This could include using cyberNFTs to authenticate and authorize data access in IoT networks.\n",
      "* **Developing a system for secure and decentralized cyberNFT-based threat intelligence sharing**: This idea involves developing a system for secure and decentralized threat intelligence sharing using cyberNFTs. This could include using cyberNFTs to incentivize threat intelligence sharing and to track and analyze threat intelligence data.\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------------------------------------------------------------\n",
    "KeyError                                  Traceback (most recent call last)\n",
    "Cell In[176], line 1\n",
    "----> 1 response = idea_retriever_chain.invoke({\"input\": \"CyberNFTs: Conceptualizing a decentralized and reward-driven intrusion detection system with ML\"})\n",
    "\n",
    "File c:\\Users\\j\\.vscode\\Resume_search\\resume-search\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5313, in invoke(self, input, config, **kwargs)\n",
    "   5310 def get_output_schema(\n",
    "   5311     self, config: Optional[RunnableConfig] = None\n",
    "   5312 ) -> type[BaseModel]:\n",
    "-> 5313     if self.custom_output_type is not None:\n",
    "   5314         return super().get_output_schema(config)\n",
    "   5315     return self.bound.get_output_schema(merge_configs(self.config, config))\n",
    "\n",
    "File c:\\Users\\j\\.vscode\\Resume_search\\resume-search\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3013, in invoke(self, input, config, **kwargs)\n",
    "   3010 # invoke all steps in sequence\n",
    "   3011 try:\n",
    "   3012     for i, step in enumerate(self.steps):\n",
    "-> 3013         # mark each step as a child run\n",
    "   3014         config = patch_config(\n",
    "   3015             config, callbacks=run_manager.get_child(f\"seq:step:{i+1}\")\n",
    "   3016         )\n",
    "   3017         context = copy_context()\n",
    "\n",
    "File c:\\Users\\j\\.vscode\\Resume_search\\resume-search\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:497, in invoke(self, input, config, **kwargs)\n",
    "    488 def invoke(\n",
    "...\n",
    "    161     )\n",
    "    162     raise KeyError(msg)\n",
    "--> 163 return inner_input\n",
    "\n",
    "KeyError: \"Input to ChatPromptTemplate is missing variables {'novel_ideas', 'refined_ideas', 'refined_list', 'proposed_ideas', 'relevant_ideas'}.  Expected: ['context', 'input', 'novel_ideas', 'proposed_ideas', 'refined_ideas', 'refined_list', 'relevant_ideas'] Received: ['input', 'context']\\nNote: if you intended {novel_ideas} to be part of the string and not a variable, please escape it with double curly braces like: '{{novel_ideas}}'.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
